{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Word Moverâ€™s Distance "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://tedboy.github.io/nlps/generated/generated/gensim.models.Word2Vec.wmdistance.html\n",
    "    \n",
    "https://www.yelp.com/dataset_challenge/dataset`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~~~~~\n",
    "\n",
    "WMD: gensim.models.Word2Vec.wmdistance\n",
    "\n",
    "1. Download the data from https://www.yelp.com/dataset_challenge/dataset\n",
    "2. Preprocess the data, removing stopwords, etc\n",
    "3. Filters the 'reviews' of 6 restaurants( Earl of Sandwich, Wicked Spoon, Serendipity 3, Bacchanal Buffet,\n",
    "   The Buffet, Mon Ami Gabi) from the downloaded database.\n",
    "4. Load the pretrained Google model of vectors into word2vec\n",
    "5. Convert text into word2vec.\n",
    "6. Compute the distance between the reviews and query input using word mover's distance(Word2Vec.wmdistance)\n",
    "7. Retrieve top 10 similar reviews.\n",
    "\n",
    "~~~~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "\n",
    "# --- NLTK PACKAGE ---\n",
    "import nltk\n",
    "# Tokenizers\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize, PunktSentenceTokenizer, RegexpTokenizer\n",
    "# Stemming and Lemmatizing\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "# Stopwords\n",
    "from nltk.corpus import stopwords, state_union, brown, movie_reviews, treebank\n",
    "# Wordnet\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "# --- GENSIM PACKAGE ---\n",
    "import gensim\n",
    "from gensim.models import Word2Vec, doc2vec, Doc2Vec\n",
    "from gensim.models.tfidfmodel import TfidfModel\n",
    "from gensim import corpora, models, similarities\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading WMD Google Pre-trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "WMD_model = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin.gz', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## OUR MODEL\n",
    "#  model = Word2Vec(words, size = 100, window = 10, hs=1, negative=0, workers = 4, min_count=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query = \"Who is Pranjal ?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = '''My name is Pranjal Pathak. \n",
    "          My gender is Male. I am 23 years old. \n",
    "          I live in Bangalore. I like driving. \n",
    "          I have lived in Varanasi before but I like Bangalore more. \n",
    "          Phani is a nice girl. Her gender is Female.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>WMD_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My name is Pranjal Pathak.</td>\n",
       "      <td>2.611560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Phani is a nice girl.</td>\n",
       "      <td>3.309831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I am 23 years old.</td>\n",
       "      <td>3.331509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I like driving.</td>\n",
       "      <td>3.365052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I live in Bangalore.</td>\n",
       "      <td>3.378908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I have lived in Varanasi before but I like Ban...</td>\n",
       "      <td>3.408394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>My gender is Male.</td>\n",
       "      <td>3.778200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Her gender is Female.</td>\n",
       "      <td>3.869779</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence  WMD_Score\n",
       "0                         My name is Pranjal Pathak.   2.611560\n",
       "6                              Phani is a nice girl.   3.309831\n",
       "2                                 I am 23 years old.   3.331509\n",
       "4                                    I like driving.   3.365052\n",
       "3                               I live in Bangalore.   3.378908\n",
       "5  I have lived in Varanasi before but I like Ban...   3.408394\n",
       "1                                 My gender is Male.   3.778200\n",
       "7                              Her gender is Female.   3.869779"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_similarity(query, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_similarity(query, data):\n",
    "    list_distances = []\n",
    "    \n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    sentence1 = [word for word in word_tokenize(query) if word not in stop_words]\n",
    "    \n",
    "    sentences_in_document = sent_tokenize(data)\n",
    "    \n",
    "    for each_sentence in sentences_in_document:\n",
    "        sentence2 = [word for word in word_tokenize(each_sentence) if word not in stop_words]\n",
    "        similarity_distance = WMD_model.wmdistance(sentence1, sentence2)\n",
    "        list_distances.append(similarity_distance)\n",
    "        \n",
    "    WMD_Dataframe = pd.DataFrame({'Sentence': sentences_in_document, 'WMD_Score': list_distances}).sort_values(by=['WMD_Score'],ascending=True) \n",
    "    return WMD_Dataframe"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
